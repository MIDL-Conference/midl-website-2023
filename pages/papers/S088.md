---
title: "Assessing Deep Learning Methodologies for Automatic Segmentation of the Velopharyngeal Mechanism"
page_class: "paper"
---

{% from "_macros.html" import presentation, button, teaser, youtube %}

# S088 - Assessing Deep Learning Methodologies for Automatic Segmentation of the Velopharyngeal Mechanism

#### Jiebei Liu, Donald E Brown, Kazlin Mason, Stephen Baek

[% .details %]
<a class="toggle_visibility" data-selector=".abstract" data-level="3">Show abstract</a>
- <a class="toggle_visibility" data-selector=".schedule" data-level="3">Show schedule</a>
- <a href="https://openreview.net/pdf?id=OaG7pYqbs7">PDF</a>
- <a href="https://openreview.net/forum?id=OaG7pYqbs7">Reviews</a>

<p>
    <span class="abstract">
        Velopharyngeal dysfunction (VPD) results in speech, resonance, and swallowing difficulties due to inadequate separation of oral and nasal cavities by the velopharyngeal musculature. Diagnosing and treating VPD often involve multidisciplinary evaluation and specialized imaging techniques like videofluoroscopy or nasendoscopy. However, recent MRI applications have enabled non-invasive visualization of the vocal tract and VP mechanism, providing insights into the shape, size, movement, and position. In order to obtain this data, however, manual techniques are necessary, and analyses of 3D MRI data are time-consuming and not yet clinically feasible. This article aims to explore the feasibility of 3D medical image deep learning methods for segmenting soft palate, levator muscle, pharyngeal wall, and adenoids in the velopharyngeal region, overcoming current limitations and contributing to future clinical translation of this assessment methodology.
        <br>
        <span class="actions"><a class="toggle_visibility" data-level="2">Hide abstract</a></span>
    </span>
</p>

<p>
    <span class="schedule">
        Tuesday, July 11: Posters — 10:30–12:00 & 15:00–16:00<br>
        <br>
        <span class="actions"><a class="toggle_visibility" data-level="2">Hide schedule</a></span>
    </span>
</p>
[% / %]

---


### Short paper
