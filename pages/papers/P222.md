---
title: "A comparison of self-supervised pretraining approaches for predicting disease risk from chest radiograph images"
page_class: "paper"
---

{% from "_macros.html" import presentation, button, teaser, youtube %}

# P222 - A comparison of self-supervised pretraining approaches for predicting disease risk from chest radiograph images

#### Yanru Chen, Michael T Lu, Vineet K Raghu

[% .details %]
<a class="toggle_visibility" data-selector=".abstract" data-level="3">Show abstract</a>
- <a class="toggle_visibility" data-selector=".schedule" data-level="3">Show schedule</a>
- <a href="https://openreview.net/pdf?id=HzpdwXFc_Q">PDF</a>
- <a href="https://openreview.net/forum?id=HzpdwXFc_Q">Reviews</a>

<p>
    <span class="abstract">
        Deep learning is the state-of-the-art for medical imaging tasks, but requires large, labeled datasets. For risk prediction, large datasets are rare since they require both imaging and follow-up (e.g., diagnosis codes). However, the release of publicly available imaging data with diagnostic labels presents an opportunity for self and semi-supervised approaches to improve label efficiency for risk prediction. Though several studies have compared self-supervised approaches in natural image classification, object detection, and medical image interpretation, there is limited data on which approaches learn robust representations for risk prediction. We present a comparison of semi- and self-supervised learning to predict mortality risk using chest x-ray images. We find that a semi-supervised autoencoder outperforms contrastive and transfer learning in internal and external validation. 
        <br>
        <span class="actions"><a class="toggle_visibility" data-level="2">Hide abstract</a></span>
    </span>
</p>

<p>
    <span class="schedule">
        
        <br>
        <span class="actions"><a class="toggle_visibility" data-level="2">Hide schedule</a></span>
    </span>
</p>
[% / %]

---


### Spotlight presentation
